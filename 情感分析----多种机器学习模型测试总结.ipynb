{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "434ef350",
   "metadata": {},
   "source": [
    "### Step1:读取评论文件"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c85424c",
   "metadata": {},
   "source": [
    "加载评论信息文件, 并获取所有评论内容及情感"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e6109f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "def loadCommentFile(file_name):\n",
    "    all_sentences = []\n",
    "    \n",
    "    with open(file_name, 'r', encoding='utf-8') as fp:                                    #读取文件\n",
    "        reader = csv.reader(fp)\n",
    "        \n",
    "        #读取迭代器内的所有评论信息\n",
    "        all_sentences = np.array([[comment[0],comment[1]] for comment in reader])         #保存格式[['评论1','评论情感标签']]         \n",
    "    \n",
    "    print('Step1:read {} comments in file...'.format(len(all_sentences)))\n",
    "    return all_sentences                                                                  #返回numpy数组形式的所有评论内容及对应标签"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61836c90",
   "metadata": {},
   "source": [
    "### Step2: 去除重复评论信息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22325f08",
   "metadata": {},
   "source": [
    "去除评论数据集中的重复评论信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7ec998d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def removeSameComment(all_sentences):\n",
    "    \n",
    "    data = pd.DataFrame(all_sentences)\n",
    "    same_sentence_num = data.duplicated().sum()                                           #统计重复的评论内容个数\n",
    "    \n",
    "    if same_sentence_num > 0:\n",
    "        print('Step2:remove {} of same comments...'.format(same_sentence_num))\n",
    "        data = data.drop_duplicates()                                                     #删除重复的评论内容  \n",
    "    \n",
    "    return data.values                                                                   #返回numpy数组形式的评论内容信息\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef71ae59",
   "metadata": {},
   "source": [
    "### Step3: 使用jieba库进行分词操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b432db",
   "metadata": {},
   "source": [
    "使用jieba库对中文评论语句及逆行切分操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "54876de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "\n",
    "def getAllWords(all_sentences):\n",
    "    all_words = []\n",
    "    \n",
    "    for sentence in all_sentences:\n",
    "        words = jieba.lcut(sentence[0])                                                  #将评论切词，并存放所有切分后的评论语句\n",
    "        all_words.append(words)\n",
    "    \n",
    "    print('Step3:jieba cut successfully...')\n",
    "    return np.array(all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c958feb",
   "metadata": {},
   "source": [
    "### Step4: 去除停用词"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5a54ba",
   "metadata": {},
   "source": [
    "去除评论词语中已经停用的词语"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a297a57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopWords(file_name, all_words):\n",
    "    stop_words = []\n",
    "    with open(file_name, 'r', encoding='utf-8') as fp:                      #读取所有停用词\n",
    "        stop_words = fp.read().split('\\n')                                   #存到stop_words列表中(以换行符切分)\n",
    "    \n",
    "    for sentence in all_words:                                              #双重循环去除评论中的停用词\n",
    "        for word in sentence:\n",
    "            if word in stop_words:\n",
    "                sentence.remove(word)\n",
    "    \n",
    "    print('Step4:remove stop-words successfully...')\n",
    "    return np.array(all_words)                                              #以numpy数组返回\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b72efb7",
   "metadata": {},
   "source": [
    "### Step5: 生成词典"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779359d2",
   "metadata": {},
   "source": [
    "将所有评论信息中存在的词语生成一个词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "05bea95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDictionary(all_words):\n",
    "    dictionary = []\n",
    "    \n",
    "    for sentence in all_words:\n",
    "        for word in sentence:\n",
    "            \n",
    "            if word not in dictionary:\n",
    "                dictionary.append(word)                                     #将所有评论中出现的词语存入词典\n",
    "    \n",
    "    print('Step5:{} words in total...'.format(len(dictionary)))\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184e7ad8",
   "metadata": {},
   "source": [
    "### Step6: 生成one-hot编码(暂未用到)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c86af74",
   "metadata": {},
   "source": [
    "把所有评论中的词语信息都进行编码，编码形式为one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "50270a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOneHot(dictionary):\n",
    "    one_hots = []\n",
    "    \n",
    "    for index,word in enumerate(dictionary):              #使用one-hot编码把出现的词语转化为向量\n",
    "        one_hot = np.zeros(len(dictionary))\n",
    "        one_hot[index] = 1\n",
    "        \n",
    "        one_hots.append(one_hot)\n",
    "    \n",
    "    print('Step6:one-hot encoding successfully...')\n",
    "    return np.array(one_hots)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df32f1c1",
   "metadata": {},
   "source": [
    "### Step7: Word2vec编码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bde14b",
   "metadata": {},
   "source": [
    "将评论的词语信息以word2vec的方式进行编码，并存储(这里直接使用gensim库)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4ca19384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "def getWord2Vec(all_words):\n",
    "    \n",
    "    #调用Word2Vec模型，将所有词语信息转化为向量\n",
    "    model = Word2Vec(all_words, sg=0, vector_size=300, window=5, min_count=1, epochs=7, negative=10)\n",
    "    model.save('word2vec_model')\n",
    "    \n",
    "    print('word2vec encoding successfully...')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a367e1e",
   "metadata": {},
   "source": [
    "### Step8:封装数据预处理过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b840b50",
   "metadata": {},
   "source": [
    "封装所有的操作过程，最后结果返回所有**预处理过后的评论数组，word2vec模型，词语词典**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "90f7db12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData():\n",
    "    all_sentences = loadCommentFile('../datasets/comments.csv')\n",
    "    all_sentences = removeSameComment(all_sentences)\n",
    "    target = all_sentences[:,1]\n",
    "    all_words = getAllWords(all_sentences)\n",
    "    all_words = removeStopWords('../file/cn-stopwords.txt', all_words)\n",
    "    dictionary = getDictionary(all_words)\n",
    "    one_hots = getOneHot(dictionary)\n",
    "    \n",
    "    print('get all data successfully...')\n",
    "    \n",
    "    return all_words, target, dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e42001",
   "metadata": {},
   "source": [
    "### Step9:构建评论语句向量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e2603c",
   "metadata": {},
   "source": [
    "求和评论中每个词语的word_vector，然后取平均值，即为评论语句的向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d2f2c650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentenceVec(all_words, word2vec_model):\n",
    "    sentences_vector = []\n",
    "    \n",
    "    for sentence in all_words:\n",
    "        \n",
    "        sentence_vector = np.zeros(word2vec_model.wv.vector_size)\n",
    "        \n",
    "        #取出评论中每个单词的向量累加\n",
    "        for word in sentence:\n",
    "            sentence_vector += word2vec_model.wv.get_vector(word)\n",
    "\n",
    "        #取最终结果的平均值，作为评论语句的向量，并添加到评论向量列表中\n",
    "        sentences_vector.append(sentence_vector/len(sentence))\n",
    "    \n",
    "    #返回numpy类型的评论列表\n",
    "    return np.array(sentences_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175e6abf",
   "metadata": {},
   "source": [
    "### Step10: 拆分数据集为训练集与测试集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65ca5ae",
   "metadata": {},
   "source": [
    "调用数据预处理的封装函数进行数据预处理，将每个词语使用word2vec模型转化为向量，并将所有评论转化为向量\n",
    "\n",
    "然后对数据集进行切分为数据集与测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "dfc51354",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step1:read 13499 comments in file...\n",
      "Step2:remove 1016 of same comments...\n",
      "Step3:jieba cut successfully...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python\\lib\\site-packages\\ipykernel_launcher.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step4:remove stop-words successfully...\n",
      "Step5:15834 words in total...\n",
      "Step6:one-hot encoding successfully...\n",
      "get all data successfully...\n",
      "word2vec encoding successfully...\n",
      "train_test_split successfully!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split         #引入拆分训练集与测试集的方法\n",
    "\n",
    "all_words, target, dictionary = getData()                     #获取评论的分词形式列表、对应标签、词典\n",
    "\n",
    "word2vec_model = getWord2Vec(all_words)                       #训练Word2Vec模型\n",
    "word2vec_model.save('word2vec_model')                         #保存文件\n",
    "\n",
    "#将每一句评论信息转化为对应的评论向量\n",
    "sentences_vector = getSentenceVec(all_words, word2vec_model)\n",
    "\n",
    "#拆分数据集为训练集与测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(sentences_vector, target)\n",
    "print('train_test_split successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f28f6c",
   "metadata": {},
   "source": [
    "### Step11:训练多种监督模型，准备评论情感预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2576ebea",
   "metadata": {},
   "source": [
    "#### KNN算法模型的训练与评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "16207681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is take 0.014011383056640625 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier               #引入KNN算法模型\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)                         #K近邻模型训练中，n邻居个数越多越欠拟合，越少越过拟合\n",
    "knn.fit(X_train, y_train)                                         #训练KNN模型\n",
    "\n",
    "end = time.time()\n",
    "print('It is take {} seconds'.format(end-start))                  #输出训练所需的时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "d47b9a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:0.9629352702414015\n",
      "Test score:0.9487343800064082\n",
      "It is take 4.137312889099121 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "train_score = knn.score(X_train, y_train)\n",
    "test_score = knn.score(X_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print('Train score:{}'.format(train_score))\n",
    "print('Test score:{}'.format(test_score))\n",
    "print('It is take {} seconds'.format(end-start))                  #输出训练所需的时间"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02661a6b",
   "metadata": {},
   "source": [
    "#### 逻辑回归模型的训练与评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "7d49d20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is take 1.5031111240386963 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression              #引入LogisticRegression逻辑回归模型\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "#弱正则化对应过拟合，强正则化对应欠拟合\n",
    "logistic_regression = LogisticRegression(C=50)                    #在逻辑回归中，参数C控制正则化强弱，C越大正则化越弱，C越小正则化越强\n",
    "logistic_regression.fit(X_train, y_train)                         #训练逻辑回归模型\n",
    "\n",
    "end = time.time()\n",
    "print('It is take {} seconds'.format(end-start))                  #输出训练所需的时间\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "410034a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:0.967955565050203\n",
      "Test score:0.962191605254726\n",
      "It is take 0.032012939453125 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "train_score = logistic_regression.score(X_train, y_train)\n",
    "test_score = logistic_regression.score(X_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print('Train score:{}'.format(train_score))\n",
    "print('Test score:{}'.format(test_score))\n",
    "print('It is take {} seconds'.format(end-start))                  #输出训练所需的时间"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac5540e",
   "metadata": {},
   "source": [
    "#### 支持向量机分类器的训练与评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "34022196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is take 3.914299249649048 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC                                      #引入支持向量机分类器\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "svc = SVC(gamma=0.1, C=100)                                       #gamma控制类别的相似度程度，越小越好，C控制正则化程度，适中即可\n",
    "svc.fit(X_train, y_train)                                         #训练支持向量机分类器\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print('It is take {} seconds'.format(end-start))                  #输出训练所需的时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "261bafe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:0.9948728904080325\n",
      "Test score:0.9724447292534444\n",
      "It is take 3.5872702598571777 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "train_score = svc.score(X_train, y_train)\n",
    "test_score = svc.score(X_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print('Train score:{}'.format(train_score))\n",
    "print('Test score:{}'.format(test_score))\n",
    "print('It is take {} seconds'.format(end-start))                  #输出训练所需的时间"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638f338f",
   "metadata": {},
   "source": [
    "#### 伯努利贝叶斯模型的训练与评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "c227298b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is take 0.09700345993041992 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB                      #引入伯努利贝叶斯模型\n",
    "start = time.time()\n",
    "bernoulli_bayes = BernoulliNB()\n",
    "bernoulli_bayes.fit(X_train, y_train)                             #训练伯努利贝叶斯模型\n",
    "end = time.time()\n",
    "\n",
    "print('It is take {} seconds'.format(end-start))                  #输出训练所需的时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ac7e1b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:0.913052766502884\n",
      "Test score:0.9160525472604935\n",
      "It is take 0.11000585556030273 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "train_score = bernoulli_bayes.score(X_train, y_train)\n",
    "test_score = bernoulli_bayes.score(X_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print('Train score:{}'.format(train_score))\n",
    "print('Test score:{}'.format(test_score))\n",
    "print('It is take {} seconds'.format(end-start))                  #输出训练所需的时间"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3b9205",
   "metadata": {},
   "source": [
    "#### 决策树模型的训练与评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "12fc3e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is take 1.640122652053833 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier                  #引入决策树模型\n",
    "start = time.time()   \n",
    "decision_tree = DecisionTreeClassifier(max_depth=5)               #设置决策树的最大深度为5，避免出现过拟合现象           \n",
    "decision_tree.fit(X_train, y_train)                               #训练多项式贝叶斯模型\n",
    "end = time.time()\n",
    "\n",
    "print('It is take {} seconds'.format(end-start))                  #输出训练所需的时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "4cb2d4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:0.9573809015167699\n",
      "Test score:0.93784043575777\n",
      "It is take 0.031012535095214844 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "train_score = decision_tree.score(X_train, y_train)\n",
    "test_score = decision_tree.score(X_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print('Train score:{}'.format(train_score))\n",
    "print('Test score:{}'.format(test_score))\n",
    "print('It is take {} seconds'.format(end-start))                  #输出训练所需的时间"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9802f27",
   "metadata": {},
   "source": [
    "#### 随机森林模型的训练与评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "8ba53a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is take 19.40948247909546 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier              #引入随机森林模型\n",
    "start = time.time()\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X_train, y_train)                               #训练随机森林模型\n",
    "end = time.time()\n",
    "\n",
    "print('It is take {} seconds'.format(end-start))                  #输出训练所需的时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "24a6aebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:1.0\n",
      "Test score:0.9615507850048062\n",
      "It is take 0.35802292823791504 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "train_score = random_forest.score(X_train, y_train)\n",
    "test_score = random_forest.score(X_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print('Train score:{}'.format(train_score))\n",
    "print('Test score:{}'.format(test_score))\n",
    "print('It is take {} seconds'.format(end-start))                  #输出训练所需的时间"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c353488",
   "metadata": {},
   "source": [
    "#### 梯度提升分类器模型的训练与评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "28432f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is take 307.464230298996 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier          #引入梯度提升分类树模型\n",
    "start = time.time()\n",
    "gradient_boosting_tree = GradientBoostingClassifier()\n",
    "gradient_boosting_tree.fit(X_train, y_train)                      #训练梯度提升分类树模型\n",
    "end = time.time()\n",
    "\n",
    "print('It is take {} seconds'.format(end-start))                  #输出训练所需的时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "b8fd1074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:0.9818414868617816\n",
      "Test score:0.9602691445049664\n",
      "It is take 0.31026268005371094 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "train_score = gradient_boosting_tree.score(X_train, y_train)\n",
    "test_score = gradient_boosting_tree.score(X_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print('Train score:{}'.format(train_score))\n",
    "print('Test score:{}'.format(test_score))\n",
    "print('It is take {} seconds'.format(end-start))                  #输出训练所需的时间"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e59755",
   "metadata": {},
   "source": [
    "#### MLP神经网络多层感知机模型的训练与评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "654f8b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is take 23.577603578567505 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier                 #引入神经网络多层感知机模型\n",
    "start = time.time()\n",
    "mlp = MLPClassifier()\n",
    "mlp.fit(X_train, y_train)                                        #训练神经网络MLP多层感知机模型\n",
    "end = time.time()\n",
    "\n",
    "\n",
    "print('It is take {} seconds'.format(end-start))                  #输出训练所需的时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "2ae02591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:0.9900662251655629\n",
      "Test score:0.975008010253124\n",
      "It is take 0.07800674438476562 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "train_score = mlp.score(X_train, y_train)\n",
    "test_score = mlp.score(X_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print('Train score:{}'.format(train_score))\n",
    "print('Test score:{}'.format(test_score))\n",
    "print('It is take {} seconds'.format(end-start))                  #输出训练所需的时间"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbbe77b",
   "metadata": {},
   "source": [
    "### Step12: 使用模型随机预测评论情感"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b82695",
   "metadata": {},
   "source": [
    "取出测试集中的100条测试数据，使用**支持向量机分类器(SVC)**进行评论预测，并输出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "b466432a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学大/数据/大学/狗/听/有人/说/MacBook/适合/工科/买来/一段时间/感觉/还好/性能/很强/不愧/M1/ /Pro/没买/Max/版本/感觉/不到/32/核/GPU/16G/内存/我/够用/了/。\n",
      "Predict result : 好评\tActual results: 好评\tPredict success!\t\n",
      "\n",
      "\n",
      "开机/划痕/心情/郁闷/提醒/这种/退换货/还是/官网/买\n",
      "Predict result : 差评\tActual results: 差评\tPredict success!\t\n",
      "\n",
      "\n",
      "外形/外观/好看/ /选/颜色/对/屏幕/音效/屏幕/120hz/刷新/太爽了/ /用回/xr/真/卡/拍照/效果/拍照/清晰/运行/速度/速度/快/待机时间/玩/一把/游戏/掉电/ /续航/不错/，/其他/特色/充电/速度/快/ /23/分钟/37/ /真的/很快/了\n",
      "Predict result : 好评\tActual results: 好评\tPredict success!\t\n",
      "\n",
      "\n",
      "完美/机/听筒/缝隙/屏幕显示/正常/拍照/重点/京东/发货/真的/太牛/超级/21/号/下单/已经/错过/前两天/抢购/情况/25/号/下午/收到/货/?/?/以为/好久/我/手机/壳/没/买/快递/员/打电话/知道/又/火速/京/东京/造买/了/手机/壳/没想到/壳/不错/。/我/仔细/看过/镜头/没有/灰尘/边框/没有/划痕/绝大多数/机子/没有/，/让/知道/都/有/发出/来显/的/问题/，/外形/外观/完美/，/拍照/效果/无敌/，/运行/速度/超级\n",
      "Predict result : 好评\tActual results: 好评\tPredict success!\t\n",
      "\n",
      "\n",
      "买来/疫情/在家/办公/外观/时尚/大气/颜色/深/我心/自重/轻/出差/携带/发货/的/久/一点/但/值得/另外/，/小妹/导购/15/态度/很/好/，/赞/！\n",
      "Predict result : 好评\tActual results: 好评\tPredict success!\t\n",
      "\n",
      "\n",
      "苹果/生产/技术/工艺/真的/太赞/熟悉/开机/声音/干脆/铝合金/打造/金属/机身/科技/感/十足/16/寸/大家伙/有点/重/但是/接受/毕竟/屏蔽/啊/运行/流畅/很棒/感觉/京东/物流/真的/，/快递/小哥/服务态度/很/不错/，\n",
      "Predict result : 好评\tActual results: 好评\tPredict success!\t\n",
      "\n",
      "\n",
      "入手/打开/包装/很/惊艳/漂亮/看着/高级/安装/系统/简单/ /明/自带/OFF/运行/速度/超快/流畅/ /屏幕显示/超棒/不愧/大/品牌/，/爱/爱/！\n",
      "Predict result : 好评\tActual results: 好评\tPredict success!\t\n",
      "\n",
      "\n",
      "京东/快递/送货/很快/艰难/条件/停运/收到/电脑/保证/不错/电脑/是/理想/华为/品牌/靠得住/～/一些/激活/注册/问题/不会/操作/，/问/客服/也/是/很/耐心/解答\n",
      "Predict result : 好评\tActual results: 好评\tPredict success!\t\n",
      "\n",
      "\n",
      "运行/速度/开机/速度/特别/运行/流畅/运行/屏幕/效果/屏幕/清晰/视觉/舒适/散热/性能/用/几个/小时/发热/情况/风扇/静音/外形/外观/颜色/好看/商务/感强/上档次/轻薄/程度/厚度/合适/携带/轻便/其他/特色/隐形/摄像头/美观/，/指纹/解锁/便捷/华为/荣耀/手机/直连/文件/转移/，/触控/鼠标/快捷/功能/操作/很/方便/，/玩游戏/，/作为/办公/商务/电脑/值得/购买/，/性价比/超高\n",
      "Predict result : 好评\tActual results: 好评\tPredict success!\t\n",
      "\n",
      "\n",
      "东北/暴雪/缘故/晚到/几天/但用/时候/手感/好/更加/人/欣慰/是/高频/分辨率/用/非常/舒适/不/电池/续航/怎么样/还/观望/中/希望/令人/失望\n",
      "Predict result : 好评\tActual results: 好评\tPredict success!\t\n",
      "\n",
      "\n",
      "外观/好看/好看/颜值/爆表/开机/速度/很快/人脸识别/灵敏/屏幕/效果/很/清晰/大小/合适/电池/很/耐用/充电/速度/快/，/京东/快递/很/力\n",
      "Predict result : 好评\tActual results: 好评\tPredict success!\t\n",
      "\n",
      "\n",
      "垃圾/都/不想/说/刚刚/拿到/可惜/发现/晚/自己/看吧/，/联网/不/退/，/一点/不好/垃圾/电脑\n",
      "Predict result : 差评\tActual results: 差评\tPredict success!\t\n",
      "\n",
      "\n",
      "凌晨/付款/现在/拿到/货/迫不及待/开机/比/想象/要/薄/一点/屏幕/漂亮/宽/很窄/颜色/很/正/超级/爱/相信/品牌/，/质量/保证/下/一步/其他/配置/整齐/。\n",
      "Predict result : 好评\tActual results: 好评\tPredict success!\t\n",
      "\n",
      "\n",
      "外形/外观/简单/大气/四方/边框/拿/很/舒适/屏幕/音效/拍照/清晰/防抖/性能/不错/运行/速度/运行/不卡顿/处理/流畅/待机时间/待机/时长/比较/优秀/充满/电/不/玩游戏/正常/6/小时\n",
      "Predict result : 好评\tActual results: 好评\tPredict success!\t\n",
      "\n",
      "\n",
      "体验/感/不好/我/办公室/网络/办法/电脑/我/天天/热点/真是/方便/但是/店家/不/退货/这/不合理/这么/贵买/服务/太差/建议/买/在/外面/办事/网络/，/用/网络/不好/。\n",
      "Predict result : 差评\tActual results: 差评\tPredict success!\t\n",
      "\n",
      "\n",
      "是/太棒了/我/喜欢/运行/速度/快/屏幕/效果/好/散热/性能/好\n",
      "Predict result : 好评\tActual results: 好评\tPredict success!\t\n",
      "\n",
      "\n",
      "电脑/隔天/收到/快递/速度/很快/屏幕/90hz/效果/好/也/保护/眼睛/开机/秒/开/，/办公室/着/方便/，/整体/效果/好/这款/电脑\n",
      "Predict result : 好评\tActual results: 好评\tPredict success!\t\n",
      "\n",
      "\n",
      "不错/手机/手感/好/方方正正/着/舒服/5g/速度/很快/幸好/以前/办/大/流量/卡/流量/还够用/系统/着/流畅/，/游戏/性能/好\n",
      "Predict result : 好评\tActual results: 好评\tPredict success!\t\n",
      "\n",
      "\n",
      "电脑/毛病/多连个/蓝牙/磨磨/唧唧/一会/好使/一会/不好/千万别/入坑\n",
      "Predict result : 差评\tActual results: 差评\tPredict success!\t\n",
      "\n",
      "\n",
      "屏幕/效果/非常/运行/速度/?/外形/外观/好看/其他/特色/音响/不错/我/很/爱/大家/这部/不用/犹豫/，/冲/！\n",
      "Predict result : 好评\tActual results: 好评\tPredict success!\t\n",
      "\n",
      "\n",
      "电脑/价格/10/天降/两次/申请/保价/说/了/保价/期/，/明明/说/是/保价/一个月/，/给/说/周期\n",
      "Predict result : 差评\tActual results: 差评\tPredict success!\t\n",
      "\n",
      "\n",
      "窄/宽/加持/ /16/mac/ /整体/尺寸/上/一代/无/变化/ /争议/刘海/屏/实际/mac/系统/运行/无/影响/ /系统/工具栏/专属/位/ /复古/方正/设计/ /了/稳重/气息/ /就/符合/这代/pro/整体/定位/ / /历代/最强/芯/最强/屏/最强/扬声/系统/足够/震撼/ /回归/磁吸/ /多/拓展/接口/是/惊喜/满满/想要/换新/这代/真的/不用/了/ /体验/感拉满\n",
      "Predict result : 好评\tActual results: 好评\tPredict success!\t\n",
      "\n",
      "\n",
      "运行/速度/很快/外形/外观/很/好看\n",
      "Predict result : 好评\tActual results: 好评\tPredict success!\t\n",
      "\n",
      "\n",
      "在/买/活动/时候/价格/美丽/发货/速度/贼/质量/不错/应该/正品/挺/和/想象/中/随意/搭/好看/满意/每/都/很/满意/，/这次/选/的/宝贝/满意/，/以后/还会/一如既往/地买/包装/，/物流/，/价格/实惠/，/散热/挺/，/风扇/声/还行\n",
      "Predict result : 好评\tActual results: 好评\tPredict success!\t\n",
      "\n",
      "\n",
      "买来/上网/课用/电脑/不错/噢/而且/到货/不/熟悉/11/系统/不会/就/问/导购/37/小姐姐/，/她/耐心/解答/好/喔\n",
      "Predict result : 好评\tActual results: 好评\tPredict success!\t\n",
      "\n",
      "\n",
      "品控/之差/屏幕/三个/暗点/坏点/人脸/解锁/几次/正常/识别/换货/等于/抽奖/315\n",
      "Predict result : 差评\tActual results: 差评\tPredict success!\t\n",
      "\n",
      "\n",
      "轻薄/程度/轻薄/外形/外观/非常/好看/高级/屏幕/效果/显色/很/好/散热/性能/散热/发热/其他/特色/快递/物流/疫情/不/因素/很快/快递/疫情/原因/滞留/10/天/，/今天/到/，/包装/还是/很/不错/的/。\n",
      "Predict result : 好评\tActual results: 好评\tPredict success!\t\n",
      "\n",
      "\n",
      "运行/速度/5/秒/开机/爆赞/屏幕/效果/高色域/无色差/散热/性能/非常/静音/整机/散热\n",
      "Predict result : 差评\tActual results: 好评\tPredict fail!\t\n",
      "\n",
      "\n",
      "差评/差评/差评/差评/差评/刚/拿来/有/黑屏/电视剧/屏幕/就/花掉\n",
      "Predict result : 差评\tActual results: 差评\tPredict success!\t\n",
      "\n",
      "\n",
      "运行/速度/感觉/很快/日常/完全/问题/屏幕/效果/屏幕/流畅/非常/清晰/颜色/正/，/外形/外观/好看/，/轻薄/程度/轻薄\n",
      "Predict result : 好评\tActual results: 好评\tPredict success!\t\n",
      "\n",
      "\n",
      "对比/买下/这款/轻薄/16.1/寸/屏幕/看着/舒服/平时/做作业/，/办公/，/性能/足够/，/银色/高级/，/还/继续/探索/中\n",
      "Predict result : 好评\tActual results: 好评\tPredict success!\t\n",
      "\n",
      "\n",
      "纠结/好久/选/这个/颜色/不/沾/指纹/大小/合适/外观设计/精美/拍摄/效果/好/运行/速度/待机时间/长/，/屏幕/清晰度/高/，/手感/好\n",
      "Predict result : 好评\tActual results: 好评\tPredict success!\t\n",
      "\n",
      "\n",
      "手机/充电/头/自己/配\n",
      "Predict result : 差评\tActual results: 差评\tPredict success!\t\n",
      "\n",
      "\n",
      "买/还/几天/掉价儿/还/保价/强烈/差评\n",
      "Predict result : 差评\tActual results: 差评\tPredict success!\t\n",
      "\n",
      "\n",
      "垃圾/东西/就/几天/时间/降/700/块钱/保价/服务/没用/慎买\n",
      "Predict result : 差评\tActual results: 差评\tPredict success!\t\n",
      "\n",
      "\n",
      "隔天/收到/电脑/ /喜欢/ /朋友/推荐/买/华为/笔记本/ /是/了/好几年/说好/ /轻薄/小巧/ /携带/ /运行/速度/快/ /喜欢\n",
      "Predict result : 好评\tActual results: 好评\tPredict success!\t\n",
      "\n",
      "\n",
      "好/便携/电脑/尺寸/配置/很强/独立/显卡/荣耀/几年/产品设计/越来越/特点/！/家人/后/反馈/好/系统/很/流畅/，/十分/推荐\n",
      "Predict result : 好评\tActual results: 好评\tPredict success!\t\n",
      "\n",
      "\n",
      "到手/惊艳/ /这块/屏幕/确实/不错/ /显示/效果/很/细腻/ /1080p/16/寸大屏/确实/逐渐/淘汰/ /在/自带/管家/调/色调/ /对比度/ /也/很/ /一个/贴心/小/功能/ /开盖/开机/ /很/ /实测/七八次/样子/ /挺/灵敏/ /多/的/东西/ /慢慢/测好\n",
      "Predict result : 好评\tActual results: 好评\tPredict success!\t\n",
      "\n",
      "\n",
      "收到/笔记本/特意/了/三天/评价/感觉/整体/很/不错/速度/静音/易上/手/操作/只是/包裹/外包装/破损/，/以后/注意/，/笔记本/内包装/完好/，/推荐/购买\n",
      "Predict result : 好评\tActual results: 好评\tPredict success!\t\n",
      "\n",
      "\n",
      "登录/WIFI/显示/密码/错误/同/密码/家里/两部/华为/手机/可以/登录/WIFI/申请/售后/换货/售后/说/帮/调试/，/拿到/手机/试用/登录/WIFI/密码/错误\n",
      "Predict result : 差评\tActual results: 差评\tPredict success!\t\n",
      "\n",
      "\n",
      "感谢/服务/那么/电脑/下来/反应速度/快/我/买/游戏/本作/做/文职/的/工作/，/来看/是/问题/了/，/谢谢/，/谢谢/的/。\n",
      "Predict result : 好评\tActual results: 好评\tPredict success!\t\n",
      "\n",
      "\n",
      "粉红色/外观/电脑/颜值/挺/高/运行/速度/很快/没有/声音/散热/性能/好/，/价格/优惠\n",
      "Predict result : 好评\tActual results: 好评\tPredict success!\t\n",
      "\n",
      "\n",
      "开机/速度慢/花头/精/多\n",
      "Predict result : 差评\tActual results: 差评\tPredict success!\t\n",
      "\n",
      "\n",
      "电脑/喜欢/想象/中/一样/简单/大方/轻薄/办公/够用/运行/速度/，/到货/后用/才/评价/，/小巧玲珑/，/静谧/银/好看\n",
      "Predict result : 好评\tActual results: 好评\tPredict success!\t\n",
      "\n",
      "\n",
      "商品/发烫/退货/检修/原机/退回/，\n",
      "Predict result : 差评\tActual results: 差评\tPredict success!\t\n",
      "\n",
      "\n",
      "运行/速度/很快/ /不卡/流畅/屏幕/效果/分辨率/高/散热/性能/很/，/外形/外观/很/简约/大气\n",
      "Predict result : 好评\tActual results: 好评\tPredict success!\t\n",
      "\n",
      "\n",
      "超级/轻薄/外观/满分/性价比/极高/值得/推荐/运行/速度/非常/！/屏幕/效果/非常/清晰/散热/性能/非常/，/外形/外观/外观/10/颗星/，/轻薄/程度/非常/轻薄\n",
      "Predict result : 好评\tActual results: 好评\tPredict success!\t\n",
      "\n",
      "\n",
      "不好/ /屏幕/一点/不灵敏\n",
      "Predict result : 差评\tActual results: 差评\tPredict success!\t\n",
      "\n",
      "\n",
      "没用过/贵/笔记本/苹果/笔记本/很/精致\n",
      "Predict result : 好评\tActual results: 好评\tPredict success!\t\n",
      "\n",
      "\n",
      "颜色/漂亮/存储空间/足够/处理器/速度/满足/需求/发货/速度/很快/满意/，/推荐/购买/上班族/足够/，/打游戏/可以/，/速度/杠杠/滴\n",
      "Predict result : 好评\tActual results: 好评\tPredict success!\t\n",
      "\n",
      "\n",
      "本次测试预测准确度为: 0.98\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "dic_len = len(dictionary)\n",
    "\n",
    "start = random.randint(100,2400)\n",
    "\n",
    "#从测试集中随机抽取50条数据，准备测试\n",
    "X_data = X_test[start:start+50]\n",
    "y_data = y_test[start:start+50]\n",
    "\n",
    "success_test = 0\n",
    "\n",
    "#对 50 条评论信息进行预测\n",
    "for sequence_index in range(len(X_data)):\n",
    "    \n",
    "    #找到该评论在数组中的位置\n",
    "    loc = np.where((sentences_vector == X_data[sequence_index]).all(axis=1))\n",
    "    \n",
    "    #输出该评论语句\n",
    "    print('/'.join(all_words[loc[0][0]]))\n",
    "    \n",
    "    \n",
    "    res = svc.predict([X_data[sequence_index]])                #使用支持向量机进行预测\n",
    "    \n",
    "\n",
    "    #0 代表好评， 1代表差评\n",
    "    if res == '0':             \n",
    "        print('Predict result : 好评', end='\\t')              #输出好评\n",
    "    else:              \n",
    "        print('Predict result : 差评', end='\\t')             #否则输出差评\n",
    "    \n",
    "    #实际该评论的结果\n",
    "    if y_data[sequence_index] == '0':\n",
    "        print('Actual results: 好评', end='\\t')\n",
    "    else:   \n",
    "        print('Actual results: 差评', end='\\t')\n",
    "        \n",
    "    #判断是否预测正确\n",
    "    if res == y_data[sequence_index]:\n",
    "        print('Predict success!', end='\\t')\n",
    "        success_test += 1\n",
    "    else:\n",
    "        print('Predict fail!', end='\\t')\n",
    "\n",
    "\n",
    "    print('\\n\\n')\n",
    "\n",
    "print('本次测试预测准确度为: {}'.format(success_test/50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3201a67e",
   "metadata": {},
   "source": [
    "可见，支持向量机模型对结果的预测准确度达到98%，也较为不错"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5607fbfa",
   "metadata": {},
   "source": [
    "### 表格对比各机器学习模型在情感识别方面的性能"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825e337e",
   "metadata": {},
   "source": [
    "前提，评论文本信息已经完成一系列的预处理操作，如"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53047a32",
   "metadata": {},
   "source": [
    "- 评论去重\n",
    "- 评论分词\n",
    "- 去除停用词\n",
    "- one-hot词向量(效率低，未用到)\n",
    "- word2vec词向量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3b47c7",
   "metadata": {},
   "source": [
    "现在列举各机器学习模型对于评论情感分析的性能"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cfbc91",
   "metadata": {},
   "source": [
    "|  模型名称   | 训练耗时  | 测试耗时  | 训练集预测精度  | 测试集预测精度  |\n",
    "|  :----  | :----:  | :----:  | :----:  | :----:  |\n",
    "| KNN模型  | 0.01401s | 4.13731s | 96.3% | 94.9% |\n",
    "| 逻辑回归模型  | 1.50311s | 0.03201s | 96.8% | 96.2% |\n",
    "| 支持向量机模型  | 3.91430s | 3.58727s | 99.5% | 97.2% |\n",
    "| 伯努利贝叶斯模型  | 0.09700s | 0.11001s | 91.3% | 91.6% |\n",
    "| 决策树模型  | 1.64012s | 0.03101s | 95.7% | 93.8% |\n",
    "| 随机森林模型  | 19.40948s | 0.35802s | 100% | 96.2% |\n",
    "| 梯度提升分类树模型  | 307.46423s | 0.31026s | 98.2% | 96.0% |\n",
    "| 神经网络MLP多层感知器模型  | 23.57760s | 0.07800 | 99.0% | 97.5% |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcd5c2a",
   "metadata": {},
   "source": [
    "### 小结"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb00ce0",
   "metadata": {},
   "source": [
    "本次统计测试结果不一定完全准确，因为没有涉及到细节的调参问题或者数据缩放问题\n",
    "\n",
    "尤其是随机森林模型，过拟合较为严重，后续若有新的学习进展，会陆续更新改进，若有小伙伴们有疑问或指导，欢迎下方留言"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
